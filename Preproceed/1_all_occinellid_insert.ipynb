{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import reverse_geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlontogps(df_all):\n",
    "    df_all.Latitude = df_all.Latitude.astype(float)\n",
    "    df_all.Longitude = df_all.Longitude.astype(float)\n",
    "\n",
    "    df_all_gps = []\n",
    "    for i in tqdm(range(len(df_all))):\n",
    "        df_all_gps.append( (df_all.Latitude[i], df_all.Longitude[i]) )\n",
    "        \n",
    "    df_all['gps'] = df_all_gps\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "\n",
    "def remove_sp(df_all):\n",
    "    sp_idx = []\n",
    "    for i in range(len(df_all)):\n",
    "        if 'sp.' in df_all.Species[i]:\n",
    "            sp_idx.append(i)\n",
    "    df_all= df_all.drop(sp_idx).reset_index(drop=True)\n",
    "\n",
    "    under_30 = []\n",
    "    for i in range(len(df_all.Species.value_counts())):\n",
    "        if df_all.Species.value_counts()[i]<30:\n",
    "            under_30.append(df_all.Species.value_counts().index[i])\n",
    "            \n",
    "    drop_30 = []\n",
    "    for i in tqdm(range(len(df_all.Species))):\n",
    "        for j in under_30:\n",
    "            if df_all.Species[i] == j:\n",
    "                drop_30.append(i)        \n",
    "    df_all= df_all.drop(drop_30).reset_index(drop=True)            \n",
    "                \n",
    "    one_letter = []\n",
    "    for i in df_all.Species.value_counts().index:\n",
    "        if len(i.split(' ')) == 1:\n",
    "            one_letter.append(i)    \n",
    "            \n",
    "    drop_one = []\n",
    "    for i in tqdm(range(len(df_all.Species))):\n",
    "        for j in one_letter:\n",
    "            if df_all.Species[i] == j:\n",
    "                drop_one.append(i)        \n",
    "    df_all = df_all.drop(drop_one).reset_index(drop=True)\n",
    "\n",
    "    print(\"final species length:\",len(df_all.Species.unique()))\n",
    "\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def dropdup(frame):\n",
    "    print(\"frame length:\", len(frame))\n",
    "    frame = frame[frame.public_positional_accuracy<=1000].reset_index(drop=True)\n",
    "    frame = frame[(frame.Latitude!=0.0)&(frame.Longitude!=0.0)].reset_index(drop=True)\n",
    "    frame = frame[['Source','State','Year','Species','Latitude','Longitude','public_positional_accuracy']].drop_duplicates(['Year','Species','Latitude','Longitude'],keep='first').reset_index(drop=True)\n",
    "    print(\"frame length after eda:\", len(frame))\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. all_coccinellid table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"../Data/1st_manipulated_data/_all_coccinellid.csv\")\n",
    "\n",
    "df_all = df_all[[ 'Source', 'State', 'Year', 'Species', 'Latitude',\n",
    "       'Longitude', 'public_positional_accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = remove_sp(df_all)\n",
    "df_all = dropdup(df_all)\n",
    "df_all = latlontogps(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.Source.fillna('Undefined',inplace=True)\n",
    "df_all.gps = [str(i).split(',')[0].replace(\"(\",\"\")+\" \"+str(i).split(',')[1].replace(\")\",\"\") for i in df_all.gps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanstate = df_all[df_all.State.isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STATE 목록 체킹!\n",
    "state_check=[]\n",
    "nousa = []\n",
    "for i in nanstate.index:\n",
    "\n",
    "    #create a list of US states (and the District of Columbia)\n",
    "    state_names = [\"Alabama\", \"Arkansas\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \n",
    "                    \"District of Columbia\",\"Delaware\", \"Florida\",\"Georgia\", \"Iowa\", \"Idaho\", \n",
    "                    \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \n",
    "                    \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \n",
    "                    \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \n",
    "                    \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\",\"South Dakota\", \n",
    "                    \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\",\n",
    "                    # \"Alaska\", \n",
    "                    # \"Hawaii\",\n",
    "                    \"Wyoming\", \"Alberta\", \"British Columbia\", \"Ontario\", \"Manitoba\", \"Quebec\", \"Saskatchewan\"]\n",
    "\n",
    "    #get the metadata for the latitude and longitude coordinates\n",
    "    results = reverse_geocoder.search((nanstate['Latitude'][i], nanstate['Longitude'][i]))\n",
    "\n",
    "    #check if the location is a US state (the 'admin1' variable is where US states are listed)\n",
    "    if results[0]['admin1'] in state_names:\n",
    "        state_check.append(results[0]['admin1'])\n",
    "    else:\n",
    "        state_check.append(results[0]['admin1'])\n",
    "        nousa.append(results[0]['admin1'])\n",
    "\n",
    "nanstate['State'] = state_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = []\n",
    "for j in range(len(nanstate)):\n",
    "    for i in set(nousa):\n",
    "        if nanstate.State[j] == i:\n",
    "            drop_idx.append(j)\n",
    "\n",
    "nanstate = nanstate.drop(drop_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_all,nanstate]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all =  df_all.sort_values(by=['Year','Latitude','Longitude']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST, MAKE CSV.\n",
    "df_all[[ 'Source', 'State', 'Year', 'Species', 'Latitude',\n",
    "       'Longitude', 'public_positional_accuracy']].to_csv(\"../Data/1st_manipulated_data/_all_coccinellid_Preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"mysql+pymysql://root:'passwordinput'@localhost:3306/ladybug_project?charset=utf8\", encoding='utf-8')\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "# except ',' to avoid error\n",
    "import pandas as pd\n",
    "df_all.to_sql(name=\"all_coccinellid\", con=engine, if_exists='append', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e7f64e5f794f3d9e14a1c6aa6032c55619d5e8f9c2735175e834e99d666003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
