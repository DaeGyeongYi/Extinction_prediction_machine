{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import pymysql\n",
    "from mlpckg.util_method import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB에서 불러오기\n",
    "db = pymysql.connect(host='localhost'\n",
    "                    ,port = 3306\n",
    "                    ,user='root'\n",
    "                    ,password='23359584'\n",
    "                    ,db='ladybug_project'\n",
    "                    ,charset='utf8') \n",
    "\n",
    "cursor = db.cursor() \n",
    "sql = \"SELECT * FROM all_coccinellid\"\n",
    "\n",
    "df_all = pd.read_sql_query(sql, db)\n",
    "\n",
    "db.close()\n",
    "#csv\n",
    "# df_all = pd.read_csv('./Data/1st_manipulated_data/_all_coccinellid_Preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab = df_all[(df_all.Species=='Harmonia axyridis')|(df_all.Species=='Coccinella septempunctata')].reset_index(drop=True)\n",
    "\n",
    "df_ab_struct = df_ab[(df_ab.Source != 'I-naturalist')&\n",
    "       (df_ab.Source != 'The Lost Ladybugs')&\n",
    "       (df_ab.Source !='Bugguide.net')].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "df_presence = df_all[(df_all.Species=='Coccinella novemnotata')|(df_all.Species=='Coccinella transversoguttata')|\n",
    "                     (df_all.Species=='Hippodamia parenthesis')|(df_all.Species=='Adalia bipunctata')]\n",
    "\n",
    "df_presence.to_csv(\"../Data/1st_manipulated_data/presence_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are two ways to select absence data points. You can choose the way you like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1. select absence, We thought that about 10 percent of all absence data points were appropriate\n",
    "random_sampled_absence = df_ab.iloc[random.sample(list(df_ab.index), k=int(len(df_ab)/10))].sort_values(by=[]).reset_index(drop=True)\n",
    "\n",
    "random_sampled_absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2. This method randomly extracts absence in the state to be proportional to the frequency of appearance in the state of the entire presence data. \n",
    "# To avoid clumping, pull out the indexes of rows aligned by coordinate at regular intervals.\n",
    "it = ['Coccinella novemnotata',\n",
    "'Coccinella transversoguttata',\n",
    "'Hippodamia parenthesis',\n",
    "'Adalia bipunctata']\n",
    "\n",
    "for name in it:\n",
    "    df_tmp = df_presence[df_presence.Species==name].reset_index(drop=True)\n",
    "    #비율 측정\n",
    "    ratio = 3 # Larger ratio returns more absence data points\n",
    "    N=int(len(df_tmp)*ratio) \n",
    "    df_state = (df_tmp.State.value_counts()/len(df_tmp))*N\n",
    "\n",
    "    #비율에 따라 분모 x 생성\n",
    "    state_x ={}\n",
    "    for i in df_state.index:\n",
    "        if i in df_ab.State.unique():\n",
    "            if int(len(df_ab[df_ab.State==i].index) / df_state[df_state.index==i][0]) != 0:\n",
    "                state_x[i]=int(len(df_ab[df_ab.State==i].index) / df_state[df_state.index==i][0])\n",
    "            else:\n",
    "                state_x[i] = 1 \n",
    "\n",
    "\n",
    "\n",
    "    #             \n",
    "    many_idx = []\n",
    "    for i in tqdm(df_state.index):\n",
    "        #필요한 숫자가 후보군 전체보다 클 때\n",
    "        if (len(df_ab[df_ab.State==i].index)) < df_state[i]:\n",
    "                for j in range(len(df_ab[df_ab.State==i].index)):\n",
    "                    if (j%(state_x[i])) == 0:\n",
    "                        many_idx.append(df_ab[df_ab.State==i].index[j])\n",
    "        else:\n",
    "            for j in range(len(df_ab[df_ab.State==i].index)):\n",
    "                if (j%(state_x[i]+1)) == 0:\n",
    "                    many_idx.append(df_ab[df_ab.State==i].index[j])\n",
    "\n",
    "\n",
    "    #타겟종의 absence후보들 선정완료된 dataframe생성\n",
    "    df_abs = df_ab.iloc[many_idx].reset_index(drop=True)\n",
    "      \n",
    "    \n",
    "    # 만약 구조적데이터의 개수가 presence가 더 많다면!\n",
    "    if len(df_tmp[(df_tmp.Source != 'I-naturalist')&\n",
    "       (df_tmp.Source != 'The Lost Ladybugs')&\n",
    "       (df_tmp.Source !='Bugguide.net')]) > \\\n",
    "        len(df_abs[(df_abs.Source != 'I-naturalist')&\n",
    "        (df_abs.Source != 'The Lost Ladybugs')&\n",
    "        (df_abs.Source !='Bugguide.net')]):\n",
    "        index=[]\n",
    "        for i in df_tmp.State.unique():\n",
    "            if len(df_ab_struct[df_ab_struct.State==i].index) <= 4:\n",
    "                for j in range(len(df_ab_struct[df_ab_struct.State==i].index)):\n",
    "                        index.append(df_ab_struct[df_ab_struct.State==i].index[j])\n",
    "            else:\n",
    "                if len(df_ab_struct[df_ab_struct.State==i].index) <6:\n",
    "                    for t in (random.sample(list(df_ab_struct[df_ab_struct.State==i].index), k=4)):\n",
    "                        index.append(t)\n",
    "                else:\n",
    "                    for t in (random.sample(list(df_ab_struct[df_ab_struct.State==i].index), k=6)):\n",
    "                        index.append(t)\n",
    "\n",
    "\n",
    "        appendix = df_ab_struct.iloc[index].reset_index(drop=True)\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "    #final dataframe is here. ex) novem_fin , trans_fin...\n",
    "    globals()['{}_fin'.format(name.split(\" \")[1][:5])] = pd.concat([df_tmp,df_abs,appendix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of absence point \n",
    "for name in it:\n",
    "    print(len(globals()['{}_fin'.format(name.split(\" \")[1][:5])][globals()['{}_fin'.format(name.split(\" \")[1][:5])].Species!=name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose what you want and to_csv.\n",
    "\n",
    "#_____.to_csv(\"../Data/1st_manipulated_data/absence_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. INSERT TO DB\n",
    "if you want to insert 'df_target' to db \\\n",
    "execute this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlontogps(df_all):\n",
    "    df_all.Latitude = df_all.Latitude.astype(float)\n",
    "    df_all.Longitude = df_all.Longitude.astype(float)\n",
    "\n",
    "    df_all_gps = []\n",
    "    for i in tqdm(range(len(df_all))):\n",
    "        df_all_gps.append( (df_all.Latitude[i], df_all.Longitude[i]) )\n",
    "        \n",
    "    df_all['gps'] = df_all_gps\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_absence = pd.read_csv(\"../Data/1st_manipulated_data/absence_only.csv\")\n",
    "df_presence = pd.read_csv(\"../Data/1st_manipulated_data/presence_only.csv\")\n",
    "\n",
    "\n",
    "df_absence = df_absence[[ 'Source', 'State', 'Year', 'Species', 'Latitude',\n",
    "       'Longitude', 'public_positional_accuracy']]\n",
    "\n",
    "df_presence = df_presence[[ 'Source', 'State', 'Year', 'Species', 'Latitude',\n",
    "       'Longitude', 'public_positional_accuracy']]\n",
    "\n",
    "\n",
    "df_target = pd.concat([df_presence,df_absence]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13601/13601 [00:00<00:00, 72153.78it/s]\n"
     ]
    }
   ],
   "source": [
    "df_target = latlontogps(df_target)\n",
    "df_target.Source.fillna('Undefined',inplace=True)\n",
    "df_target.gps = [str(i).split(',')[0].replace(\"(\",\"\")+\" \"+str(i).split(',')[1].replace(\")\",\"\") for i in df_target.gps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_all_columned = df_target\n",
    "df_target = df_target[['Year', 'Species', 'gps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(host='localhost'\n",
    "                    ,port = 3306\n",
    "                    ,user='root'\n",
    "                    ,password='23359584'\n",
    "                    ,db='ladybug_project'\n",
    "                    ,charset='utf8') \n",
    "\n",
    "cursor = db.cursor() \n",
    "\n",
    "insert_table_sql = \"INSERT INTO selected_target(`Year`,`Species`,`gps`) VALUES (%s,%s,%s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_target)):\n",
    "    cursor.execute(insert_table_sql,tuple(df_target.values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. something to think about (not essential)\n",
    "별로 크지도 않은 데이터인데 외래키로 묶어서 다시 불러올때 조건문때문에 귀찮아질 이유가 있나?\\\n",
    "pk키 기준으로 결국 한줄 씩 다 읽어들이고 나서야 불러올텐데 느려지는 것 아닌가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"mysql+pymysql://root:23359584@localhost:3306/ladybug_project?charset=utf8\", encoding='utf-8')\n",
    "conn = engine.connect()\n",
    "\n",
    "\n",
    "# except ',' to avoid error\n",
    "import pandas as pd\n",
    "df_target_all_columned.to_sql(name=\"target_allcolumned\", con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e7f64e5f794f3d9e14a1c6aa6032c55619d5e8f9c2735175e834e99d666003"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
